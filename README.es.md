# [üá∫üá∏](README.md)

# üõçÔ∏è E-Commerce con UI Generativa

Este repositorio muestra una experiencia moderna de chatbot de e-commerce construida con **LangGraph.js** y **Next.js**, demostrando c√≥mo los Modelos de Lenguaje Grandes (LLMs) pueden generar componentes de UI din√°micos e interactivos en lugar de solo simple texto.

El n√∫cleo de este proyecto es un agente que ayuda a los usuarios a encontrar LaptopsüíªÔ∏è, pero con un giro: renderiza listas de productos directamente en la interfaz de chat, permitiendo una interacci√≥n fluida y una mejor experiencia de usuario.

<img src="./pics/llm-ui-response-2025-06-25_19-03.png" alt="Interfaz de chat del agente mostrando una conversaci√≥n de b√∫squeda de port√°tiles donde un usuario solicita port√°tiles por menos de $2000. El asistente de IA responde con 'Found 3 products matching your target price range' y muestra tres tarjetas de producto de port√°tiles en una disposici√≥n de cuadr√≠cula. Cada tarjeta muestra una imagen de un port√°til con componentes internos visibles y el precio. La interfaz tiene un fondo blanco limpio con burbujas de mensaje con borde morado e incluye un campo de entrada de mensaje en la parte inferior con un bot√≥n 'Send'. La interacci√≥n demuestra la funcionalidad de UI generativa donde la IA devuelve datos de productos estructurados como componentes de UI interactivos en lugar de texto plano." width="700">

## ‚ú® Caracter√≠sticas Clave

- **UI Generativa**: El agente LLM devuelve componentes de React(dentro del shadow DOM), no solo texto.
- **Arquitectura de Agente**: Construido con [LangGraph.js](https://langchain-ai.github.io/langgraphjs/) para una orquestaci√≥n de agentes robusta y con estado (_stateful_).
- **Herramientas Avanzadas**: El agente utiliza herramientas personalizadas para b√∫squeda sem√°ntica y filtrado preciso a nivel de base de datos.
- **Stack Moderno**: [Next.js](https://nextjs.org/), [Turborepo](https://turborepo.com/), [Prisma](https://www.prisma.io/), y PostgreSQL de [Supabase](https://supabase.com/) con `pgvector`.

## üöÄ Primeros Pasos

### 1. Configuraci√≥n del Proyecto

Este proyecto fue inicializado usando la herramienta `create-agent-chat-app`, que configura una estructura de monorepo con [Turborepo](https://turborepo.com/).

```bash
# Clona el repositorio
git clone <your-repo-url>
cd <your-repo-name>

# Instala las dependencias
pnpm install

# Configura tus variables de entorno
# Crea un archivo .env en el directorio ra√≠z bas√°ndote en .env.example
cp .env.example .env

# Ejecuta el servidor de desarrollo
pnpm run dev
```

El monorepo contiene dos paquetes principales:

- `apps/agents`: El coraz√≥n de nuestra aplicaci√≥n. Contiene los agentes de LangGraph, las herramientas y la l√≥gica del servidor.
- `apps/web`: El frontend de Next.js que proporciona la interfaz de chat.

### 2. Configuraci√≥n de la Base de Datos

Usamos Prisma como nuestro ORM sobre una base de datos **PostgreSQL de Supabase**.

Antes de empezar, aseg√∫rate de tener:

1.  Habilitada la extensi√≥n [`vector`](https://supabase.com/docs/guides/database/extensions/pgvector) en tu proyecto de Supabase para la b√∫squeda por similitud de vectores (_vector similarity search_).
2.  Creada la funci√≥n `match_documents` requerida por la integraci√≥n de LangChain. M√°s informaci√≥n [aqu√≠](https://js.langchain.com/docs/integrations/vectorstores/supabase/).

## üîß Configuraci√≥n del Agente

La configuraci√≥n principal de LangGraph reside en `langgraph.json`. Este archivo orquesta las diferentes partes de nuestra aplicaci√≥n de agente.

```json:langgraph.json
{
  "node_version": "20",
  "dependencies": ["."],
  "graphs": {
    "laptops": "./apps/agents/src/ecommerce/graph.ts:graph"
  },
  "ui": {
    "laptops": "./apps/agents/src/agents-uis/index.tsx"
  },
  "env": ".env"
}
```

- `graphs.laptops`: Define el punto de entrada a nuestro grafo personalizado. El sufijo `:graph` apunta a la variable del grafo exportada y compilada dentro del archivo.
- `ui.laptops`: Especifica la ruta a los componentes de React que el agente puede renderizar.

El grafo de nuestro agente est√° definido en `apps/agents/src/ecommerce/graph.ts` y se compila en un flujo de trabajo (_workflow_) ejecutable.

```typescript:apps/agents/src/ecommerce/graph.ts
const workflow = new StateGraph(GraphState, ConfigurationSchema)
  // Define los nodos
  .addNode('agent', agent)
  .addNode('tools', toolNode)
  // Define las aristas
  .addEdge(START, 'agent')
  .addConditionalEdges(
    'agent',
    shouldContinue, // Una funci√≥n para decidir el siguiente paso
    {
      ACTION: 'tools', // Si el agente decide usar una herramienta
      __STOP__: END,   // Si el trabajo del agente ha terminado
    },
  )
  .addEdge('tools', 'agent'); // Vuelve al agente despu√©s de la ejecuci√≥n de la herramienta

// Compila el grafo
export const graph = workflow.compile();
```

## üå± Ingesta de Datos y Embeddings

Para empezar, necesitamos poblar nuestra base de datos con datos de productos y generar _embeddings_ para la b√∫squeda sem√°ntica.

- **Script de Inicializaci√≥n (_Seeding_)**: `apps/agents/prisma/seed.ts`
- **Datos de Prueba (_Mock Data_)**: `apps/agents/prisma/product-mock.ts`

El campo m√°s importante en nuestros datos de prueba es `content`, que contiene una descripci√≥n textual de cada producto. Este texto se introduce en un modelo de _embedding_ para crear representaciones vectoriales para la b√∫squeda sem√°ntica.

- **Modelo de Embedding**: Usamos el modelo `text-embedding-3-large` de OpenAI, configurado en `apps/agents/src/ecommerce/models.ts`.
- **Vector Store**: Los _embeddings_ vectoriales son gestionados por un `ProductVectorStore` personalizado, que es una abstracci√≥n sobre el `PrismaVectorStore` de LangChain. Puedes encontrar los detalles de la implementaci√≥n [aqu√≠](https://js.langchain.com/docs/integrations/vectorstores/prisma/).
  - üßë‚Äçüî¨ **Por Diversi√≥n**: Tambi√©n escrib√≠ un _vector store_ personalizado para Supabase desde cero para explorar su funcionamiento. √âchale un vistazo en `apps/agents/src/ecommerce/supabase/vector-store.ts`.

## ü§ñ El Agente `Laptops`

El trabajo del agente `Laptops` es ayudarte a encontrar las mejores ofertas de port√°tiles de nuestra selecci√≥n de seis art√≠culos. üòÖ Este agente est√° dise√±ado para mostrar dos conceptos clave:

1.  **Componibilidad de LangChain**: C√≥mo los componentes de LangChain (LCEL) agilizan el desarrollo de aplicaciones LLM.
2.  **Orquestaci√≥n del Agente**: Qu√© es un agente y c√≥mo LangGraph gestiona su estado y su proceso de toma de decisiones.

Un gran ejemplo de la componibilidad de LCEL se encuentra en `apps/agents/src/ecommerce/nodes.ts`. El nodo `agent` utiliza un `RunnableLambda` para construir e invocar din√°micamente una cadena (_chain_) que consta de un _prompt_, un modelo y herramientas.

## üõ†Ô∏è Herramientas del Agente

Para que nuestro agente sea √∫til, lo hemos equipado con dos herramientas personalizadas:

Para esta demo he creado dos herramientas:

<table>
  <thead>
    <tr>
      <th><b>Nombre de Herramienta</b></th>
      <th><b>Par√°metros</b></th>
      <th><b>Descripci√≥n</b></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>getProductsBySemanticSearch</td>
      <td>{query:string}</td>
      <td>Consulta del usuario para buscar productos<br> 
      basada en atributos no espec√≠ficos como nombre, precio, descripci√≥n o marca.</td>
    </tr>
    <tr>
      <td>getLaptopsByPrice</td>
      <td>{<br>
    equals?: number | undefined;<br>
    lt?: number | undefined;<br>
    lte?: number | undefined;<br>
    gt?: number | undefined;<br>
    gte?: number | undefined;<br>
}</td>
      <td>Filtro de precios para port√°tiles.<br>
      las claves son operadores como equals, lt, lte, gt o gte con valores num√©ricos.</td>
    </tr>
  </tbody>
</table>             |

### `getProductsBySemanticSearch`

Esta herramienta aprovecha la b√∫squeda por similitud de vectores para encontrar productos que coincidan con la _intenci√≥n_ de la consulta de un usuario, no solo con las palabras clave. Tambi√©n usamos un _prompt_ (`apps/agents/src/ecommerce/prompts/semantic-search.ts`) para instruir al LLM que devuelva un objeto JSON, que luego parseamos. Este es un fant√°stico ejemplo de **salida estructurada** (_structured output_).

### `getLaptopsByPrice`

¬øPor qu√© usar un LLM para una consulta de precio precisa? ¬°No deber√≠as! Es mejor usar una consulta determinista a la base de datos. Esta herramienta demuestra c√≥mo un agente puede parsear inteligentemente el lenguaje natural de un usuario ("mu√©strame port√°tiles por menos de $1000") en un objeto de filtro estructurado, que conectamos directamente a nuestra consulta de Prisma. Bastante ingenioso, ¬øverdad?

## ü™Ñ UI Generativa: De Texto a Componentes Interactivos

> _El texto est√° bien, ¬°pero una UI funcional y atractiva es mejor!_

Aqu√≠ es donde ocurre la magia. Hacemos que el LLM genere componentes de React que se renderizan directamente en el chat. As√≠ es como funciona:

#### 1. Definir Componentes de UI

Creamos componentes de React est√°ndar que el LLM puede elegir renderizar. En este caso, un componente `ProductsList`.
`apps/agents/src/agents-uis/ecommerce/products-list/index.tsx`

#### 2. Registrar Componentes

Le informamos a LangGraph sobre nuestros componentes de UI registr√°ndolos en `langgraph.json` bajo la clave `ui` (como se muestra arriba).

#### 3. Emitir UI desde una Herramienta

Dentro de nuestras herramientas, usamos la utilidad `typedUi` para enviar componentes de UI al flujo de respuesta del agente. En el ejemplo de abajo, la herramienta `getProductsBySemanticSearch` encuentra productos y luego env√≠a inmediatamente un componente `products-list` a la UI.

```typescript
// Una vista simplificada de la implementaci√≥n de la herramienta
import { Command, END } from '@langchain/langgraph/prebuilt';

const getProductsBySemanticSearch = tool(async ({ query }, config) => {
  const ui = typedUi<typeof ComponentMap>(config);
  const semanticProducts = await getProducts(query);

  // 1. Crea un componente de UI para mostrar los productos
  ui.push({
    name: 'products-list',
    props: { products: semanticProducts }
  });

  // 2. Devuelve un Command para actualizar el estado y finalizar el turno
  return new Command({
    update: {
      productList: semanticProducts,
      ui: ui.items
    },
    goto: END // Va directamente al final, sin necesidad de m√°s turnos del agente
  });
});
```

#### 4. Renderizar la UI en Next.js

El frontend utiliza el _hook_ `useStreamContext` para escuchar los mensajes y componentes de UI entrantes. Cuando llega un componente de UI, se renderiza dentro del chat.
`apps/web/src/components/thread/index.tsx`

#### 5. A√±adir Interactividad a la UI

La UI generada se renderiza dentro de un **shadow DOM**, lo que significa que est√° aislada del contexto de la aplicaci√≥n principal de React. Para hacer que componentes como un bot√≥n "Add to Cart" funcionen, usamos el m√©todo `thread.submit()` para enviar datos y comandos de vuelta al agente.

> **La conclusi√≥n clave es que el Estado del Grafo del Agente es nuestra √∫nica fuente de verdad.**

Cuando un usuario hace clic en "Add to Cart", enviamos un comando al agente para que actualice su estado `productsInCart`.

<details>
<summary>üé¨ Haz clic para ver la interactividad de "A√±adir al Carrito" en acci√≥n</summary>
<img src="./pics/ui-interactivity.gif" alt="Un GIF que muestra a un usuario haciendo clic en 'A√±adir al Carrito' en una tarjeta de producto dentro del chat. Esta acci√≥n actualiza el estado del agente y lleva al usuario a una p√°gina /cart separada, donde el art√≠culo seleccionado se muestra ahora en el carrito de compras." width="600">
</details>

#### 6. Persistir el Estado entre P√°ginas (El Carrito de Compras)

La pieza final del rompecabezas es la p√°gina del carrito (`apps/web/src/app/cart/page.tsx`). Para mostrar los art√≠culos, obtiene el estado m√°s reciente directamente del _endpoint_ de estado del servidor de LangGraph (`GET /threads/{threadId}/state`), lee el array `productsInCart` y renderiza los art√≠culos. Esto asegura que el carrito est√© siempre sincronizado con el conocimiento del agente.

### 7. QR del Enlace al Repositorio

<details>
<summary>Haz clic para ver el c√≥digo QR que enlaza al repositorio de GitHub de este proyecto</summary>
<img src="./pics/repo-url-qr.png" alt="C√≥digo QR que enlaza al repositorio de GitHub para este proyecto. Escanear el c√≥digo QR dirigir√° a los usuarios al repositorio donde pueden encontrar el c√≥digo fuente y la documentaci√≥n." width="600">
</details>

## üìù Notas y Advertencias

Una nota r√°pida sobre el soporte de Prisma para `pgvector`.

- Hay un _issue_ abierto sobre el soporte nativo para los operadores de `pgvector`: [prisma/prisma#18442](https://github.com/prisma/prisma/issues/18442). La soluci√≥n actual, utilizada por la integraci√≥n oficial de LangChain, implica usar las capacidades de consulta en crudo (_raw query_) de Prisma.
- **Actualizaci√≥n de las Extensiones de Prisma**: Prisma ha anunciado planes para descontinuar la caracter√≠stica de vista previa (_preview feature_) gen√©rica `postgresqlExtensions`. En su lugar, se centrar√°n en ofrecer soporte dedicado para extensiones populares. [Lee m√°s aqu√≠](https://github.com/prisma/prisma/discussions/26136).
